{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5564f1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locality Sensitive Hashing: approximate nearest neighbor search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6779ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable accelerated linear algebra processing for Spark MLlib\n",
    "# sudo apt-get install libopenblas-base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3225eb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import BucketedRandomProjectionLSH\n",
    "from pyspark.ml.feature import MinHashLSH\n",
    "\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "dataA = [(0, Vectors.dense([1.0, 1.0]),),\n",
    "         (1, Vectors.dense([1.0, -1.0]),),\n",
    "         (2, Vectors.dense([-1.0, -1.0]),),\n",
    "         (3, Vectors.dense([-1.0, 1.0]),)]\n",
    "dfA = spark.createDataFrame(dataA, [\"id\", \"features\"])\n",
    "\n",
    "dataB = [(4, Vectors.dense([1.0, 0.0]),),\n",
    "         (5, Vectors.dense([-1.0, 0.0]),),\n",
    "         (6, Vectors.dense([0.0, 1.0]),),\n",
    "         (7, Vectors.dense([0.0, -1.0]),)]\n",
    "dfB = spark.createDataFrame(dataB, [\"id\", \"features\"])\n",
    "\n",
    "key = Vectors.dense([1.0, 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32c7405",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hashed dataset where hashed values are stored in the column 'hashes':\n",
      "+---+-----------+--------------------+\n",
      "| id|   features|              hashes|\n",
      "+---+-----------+--------------------+\n",
      "|  0|  [1.0,1.0]|[[-1.0], [0.0], [...|\n",
      "|  1| [1.0,-1.0]|[[-1.0], [0.0], [...|\n",
      "|  2|[-1.0,-1.0]|[[0.0], [-1.0], [...|\n",
      "|  3| [-1.0,1.0]|[[0.0], [-1.0], [...|\n",
      "+---+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "brp = BucketedRandomProjectionLSH(inputCol=\"features\", outputCol=\"hashes\", bucketLength=2.0, numHashTables=3)\n",
    "modelBRP = brp.fit(dfA)\n",
    "\n",
    "# Feature Transformation\n",
    "print(\"The hashed dataset where hashed values are stored in the column 'hashes':\")\n",
    "modelBRP.transform(dfA).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40e2e1f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The hashed dataset where hashed values are stored in the column 'hashes':\n",
      "+---+-----------+--------------------+\n",
      "| id|   features|              hashes|\n",
      "+---+-----------+--------------------+\n",
      "|  0|  [1.0,1.0]|[[4.7945584E7], [...|\n",
      "|  1| [1.0,-1.0]|[[4.7945584E7], [...|\n",
      "|  2|[-1.0,-1.0]|[[4.7945584E7], [...|\n",
      "|  3| [-1.0,1.0]|[[4.7945584E7], [...|\n",
      "+---+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mh = MinHashLSH(inputCol=\"features\", outputCol=\"hashes\", numHashTables=5)\n",
    "modelMH = mh.fit(dfA)\n",
    "\n",
    "# Feature Transformation\n",
    "print(\"The hashed dataset where hashed values are stored in the column 'hashes':\")\n",
    "modelMH.transform(dfA).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91b3e7ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately searching dfA for 2 nearest neighbors of the key:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adeel/spark/python/pyspark/sql/context.py:125: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------+-------+\n",
      "| id|  features|              hashes|distCol|\n",
      "+---+----------+--------------------+-------+\n",
      "|  0| [1.0,1.0]|[[-1.0], [0.0], [...|    1.0|\n",
      "|  1|[1.0,-1.0]|[[-1.0], [0.0], [...|    1.0|\n",
      "+---+----------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the locality sensitive hashes for the input rows, then perform approximate nearest neighbor search.\n",
    "# We could avoid computing hashes by passing in the already-transformed dataset, e.g.\n",
    "# `model.approxNearestNeighbors(transformedA, key, 2)`\n",
    "print(\"Approximately searching dfA for 2 nearest neighbors of the key:\")\n",
    "modelBRP.approxNearestNeighbors(dfA, key, 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24b3b30d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately searching dfA for 2 nearest neighbors of the key:\n",
      "+---+----------+--------------------+-------+\n",
      "| id|  features|              hashes|distCol|\n",
      "+---+----------+--------------------+-------+\n",
      "|  0| [1.0,1.0]|[[4.7945584E7], [...|    0.5|\n",
      "|  1|[1.0,-1.0]|[[4.7945584E7], [...|    0.5|\n",
      "+---+----------+--------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the locality sensitive hashes for the input rows, then perform approximate nearest neighbor search.\n",
    "# We could avoid computing hashes by passing in the already-transformed dataset, e.g.\n",
    "# `model.approxNearestNeighbors(transformedA, key, 2)`\n",
    "print(\"Approximately searching dfA for 2 nearest neighbors of the key:\")\n",
    "modelMH.approxNearestNeighbors(dfA, key, 2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95ea3420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:\n",
      "+---+---+-----------------+\n",
      "|idA|idB|EuclideanDistance|\n",
      "+---+---+-----------------+\n",
      "|  3|  5|              1.0|\n",
      "|  0|  4|              1.0|\n",
      "|  0|  6|              1.0|\n",
      "|  2|  7|              1.0|\n",
      "|  1|  7|              1.0|\n",
      "|  3|  6|              1.0|\n",
      "|  2|  5|              1.0|\n",
      "|  1|  4|              1.0|\n",
      "+---+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the locality sensitive hashes for the input rows, then perform approximate similarity join.\n",
    "# We could avoid computing hashes by passing in the already-transformed dataset, e.g.\n",
    "# `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`\n",
    "print(\"Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:\")\n",
    "modelBRP.approxSimilarityJoin(dfA, dfB, 1.5, distCol=\"EuclideanDistance\")\\\n",
    "    .select(col(\"datasetA.id\").alias(\"idA\"),\n",
    "            col(\"datasetB.id\").alias(\"idB\"),\n",
    "            col(\"EuclideanDistance\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f66aca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:\n",
      "+---+---+-----------------+\n",
      "|idA|idB|EuclideanDistance|\n",
      "+---+---+-----------------+\n",
      "|  3|  6|              0.5|\n",
      "|  0|  7|              0.5|\n",
      "|  0|  5|              0.5|\n",
      "|  1|  6|              0.5|\n",
      "|  2|  7|              0.5|\n",
      "|  2|  5|              0.5|\n",
      "|  1|  5|              0.5|\n",
      "|  0|  4|              0.5|\n",
      "|  2|  4|              0.5|\n",
      "|  1|  7|              0.5|\n",
      "|  0|  6|              0.5|\n",
      "|  3|  4|              0.5|\n",
      "|  3|  7|              0.5|\n",
      "|  2|  6|              0.5|\n",
      "|  1|  4|              0.5|\n",
      "|  3|  5|              0.5|\n",
      "+---+---+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the locality sensitive hashes for the input rows, then perform approximate similarity join.\n",
    "# We could avoid computing hashes by passing in the already-transformed dataset, e.g.\n",
    "# `model.approxSimilarityJoin(transformedA, transformedB, 1.5)`\n",
    "print(\"Approximately joining dfA and dfB on Euclidean distance smaller than 1.5:\")\n",
    "modelMH.approxSimilarityJoin(dfA, dfB, 1.5, distCol=\"EuclideanDistance\")\\\n",
    "    .select(col(\"datasetA.id\").alias(\"idA\"),\n",
    "            col(\"datasetB.id\").alias(\"idB\"),\n",
    "            col(\"EuclideanDistance\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0b6d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
