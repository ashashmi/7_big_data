{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33c782c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scann\n",
      "  Downloading scann-1.2.6-cp39-cp39-manylinux2014_x86_64.whl (10.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.9 MB 46 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /home/adeel/anaconda3/lib/python3.9/site-packages (from scann) (1.21.5)\n",
      "Requirement already satisfied: six in /home/adeel/anaconda3/lib/python3.9/site-packages (from scann) (1.16.0)\n",
      "Collecting tensorflow~=2.8.0\n",
      "  Downloading tensorflow-2.8.2-cp39-cp39-manylinux2010_x86_64.whl (498.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 498.0 MB 3.4 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorflow~=2.8.0->scann) (61.2.0)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[K     |████████████████████████████████| 65 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: wrapt>=1.11.0 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorflow~=2.8.0->scann) (1.12.1)\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorflow-estimator<2.9,>=2.8\n",
      "  Downloading tensorflow_estimator-2.8.0-py2.py3-none-any.whl (462 kB)\n",
      "\u001b[K     |████████████████████████████████| 462 kB 2.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorflow~=2.8.0->scann) (3.6.0)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[K     |████████████████████████████████| 42 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorflow~=2.8.0->scann) (3.19.1)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "\u001b[K     |████████████████████████████████| 126 kB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorflow~=2.8.0->scann) (1.42.0)\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 3.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 2.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorflow~=2.8.0->scann) (4.1.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/adeel/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow~=2.8.0->scann) (0.37.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.9 MB 3.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (2.27.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (1.33.0)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[K     |████████████████████████████████| 781 kB 3.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (3.3.4)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/adeel/anaconda3/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (2.0.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/adeel/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/adeel/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /home/adeel/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (4.2.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/adeel/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (0.4.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/adeel/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/adeel/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/adeel/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/adeel/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow~=2.8.0->scann) (2021.10.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 2.5 MB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=910ddb0998dd3a9ef0564d27697861b4a3c233c98cb8a38d1dd412f2ee1cc9d5\n",
      "  Stored in directory: /home/adeel/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: oauthlib, requests-oauthlib, tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, absl-py, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard, opt-einsum, libclang, keras-preprocessing, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow, scann\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 flatbuffers-2.0 gast-0.5.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-14.0.1 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 scann-1.2.6 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.2 tensorflow-estimator-2.8.0 tensorflow-io-gcs-filesystem-0.26.0 termcolor-1.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96b320b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 16:27:26.557559: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-06-01 16:27:26.557588: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e780d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp:\n",
    "    response = requests.get(\"http://ann-benchmarks.com/glove-100-angular.hdf5\")\n",
    "    loc = os.path.join(tmp, \"glove.hdf5\")\n",
    "    with open(loc, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    \n",
    "    glove_h5py = h5py.File(loc, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c8908a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(glove_h5py.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418d3554",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = glove_h5py['train']\n",
    "queries = glove_h5py['test']\n",
    "print(dataset.shape)\n",
    "print(queries.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ae34dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset = dataset / np.linalg.norm(dataset, axis=1)[:, np.newaxis]\n",
    "# configure ScaNN as a tree - asymmetric hash hybrid with reordering\n",
    "# anisotropic quantization as described in the paper; see README\n",
    "\n",
    "# use scann.scann_ops.build() to instead create a TensorFlow-compatible searcher\n",
    "searcher = scann.scann_ops_pybind.builder(normalized_dataset, 10, \"dot_product\").  \\\n",
    "           tree(num_leaves=2000, num_leaves_to_search=100, training_sample_size=250000). \\\n",
    "           score_ah(2, anisotropic_quantization_threshold=0.2).reorder(100).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ce644",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall(neighbors, true_neighbors):\n",
    "    total = 0\n",
    "    for gt_row, row in zip(true_neighbors, neighbors):\n",
    "        total += np.intersect1d(gt_row, row).shape[0]\n",
    "    return total / true_neighbors.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bce0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will search the top 100 of the 2000 leaves, and compute the exact dot products \n",
    "# of the top 100 candidates from asymmetric hashing to get the final top 10 candidates.\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries)\n",
    "end = time.time()\n",
    "\n",
    "# we are given top 100 neighbors in the ground truth, so select top 10\n",
    "print(\"Recall:\", compute_recall(neighbors, glove_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b720a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing the leaves to search increases recall at the cost of speed\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries, leaves_to_search=150)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Recall:\", compute_recall(neighbors, glove_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdba7a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# increasing reordering (the exact scoring of top AH candidates) has a similar effect.\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search_batched(queries, leaves_to_search=150, pre_reorder_num_neighbors=250)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Recall:\", compute_recall(neighbors, glove_h5py['neighbors'][:, :10]))\n",
    "print(\"Time:\", end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638817b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also dynamically configure the number of neighbors returned\n",
    "# currently returns 10 as configued in ScannBuilder()\n",
    "neighbors, distances = searcher.search_batched(queries)\n",
    "print(neighbors.shape, distances.shape)\n",
    "\n",
    "# now returns 20\n",
    "neighbors, distances = searcher.search_batched(queries, final_num_neighbors=20)\n",
    "print(neighbors.shape, distances.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9218089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have been exclusively calling batch search so far; the single-query call has the same API\n",
    "start = time.time()\n",
    "neighbors, distances = searcher.search(queries[0], final_num_neighbors=5)\n",
    "end = time.time()\n",
    "\n",
    "print(neighbors)\n",
    "print(distances)\n",
    "print(\"Latency (ms):\", 1000*(end - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
